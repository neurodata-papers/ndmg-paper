{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os.path as op\n",
    "import scipy as sp\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from scipy.linalg import svd\n",
    "from scipy.linalg import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "import ndmg.stats.plotly_helper as pp\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot, plot\n",
    "from plotly import tools\n",
    "from plotly.graph_objs import *\n",
    "import colorlover as cl\n",
    "\n",
    "init_notebook_mode()\n",
    "\n",
    "np.random.seed(12345678)  # for reproducibility, set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/Users/alex/Dropbox/NeuroData/ndmg-paper/data/multisite/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: [('NKI1', 20), ('KKI2009', 21), ('HNU1', 30), ('BNU3', 47), ('BNU1', 57), ('Templeton114', 114), ('NKIENH', 198), ('SWU4', 227), ('Templeton255', 253), ('MRN1313', 1299)], \n"
     ]
    }
   ],
   "source": [
    "dpath = '/Users/alex/Dropbox/NeuroData/ndmg-paper/data/multisite/'\n",
    "# dsets = ['BNU1', 'BNU3', 'HNU1', 'KKI2009', 'MRN1313',\n",
    "#          'NKI1', 'NKIENH', 'SWU4', 'Templeton114', 'Templeton255']\n",
    "# dsets = ['BNU1', 'BNU3', 'HNU1', 'KKI2009', 'NKI1', 'NKIENH',\n",
    "#          'SWU4', 'Templeton114', 'Templeton255']\n",
    "\n",
    "dsets = ['NKI1', 'KKI2009', 'HNU1', 'BNU3', 'BNU1', 'SWU4']\n",
    "\n",
    "\n",
    "fs = OrderedDict()\n",
    "for idx, dset in enumerate(dsets):\n",
    "    fs[dset] = [root + \"/\" + fl for root, dirs, files in os.walk(os.path.join(dpath, dset))\n",
    "              for fl in files if fl.endswith(\".pkl\") and \"summary\" not in fl]\n",
    "    \n",
    "labs = ['Betweenness Centrality', 'Clustering Coefficient', 'Normalized Degree',\n",
    "        'Normalized Edge Weight', 'Eigenvalue', 'Locality Statistic-1',\n",
    "        'Density']\n",
    "# nsubs = [57, 47, 30, 21, 1299, 20, 198, 227, 114, 253]\n",
    "nsubs = [20, 21, 30, 47, 57, 114, 198, 227, 253, 1299]\n",
    "\n",
    "totalsubs = 2266\n",
    "\n",
    "print(\"Datasets: \" + \"{}, \".format(zip(dsets, nsubs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only run the below if you want to re-generate the averages for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 70 #desikan atlas\n",
    "\n",
    "def avg_data(basepath, fs):\n",
    "    \n",
    "    op = '{}/avg'.format(basepath)\n",
    "    os.system('mkdir -p {}'.format(op))\n",
    "    stats = [\"_\".join(key.split('.')[0].split('_')[1:]) for key in fs[fs.keys()[0]]]\n",
    "\n",
    "    for stat in stats:\n",
    "        print(\"Analyzing: {}\".format(stat))\n",
    "        if stat == 'edge_weight':\n",
    "            print(\"Evaluating by proxy of mean connectome -- cannot average unequal lists\")\n",
    "            continue\n",
    "        # create empty dict\n",
    "        average_dict = OrderedDict()\n",
    "        for dset in fs.keys():\n",
    "            # load the data\n",
    "            fil = [fil for fil in fs[dset] if stat in fil][0]\n",
    "            f = open(fil)\n",
    "            dat = pkl.load(f)[stat]\n",
    "            f.close()\n",
    "            \n",
    "            # average it\n",
    "            if stat == 'degree_distribution':\n",
    "                ipsi = np.zeros((len(dat['ipso_deg'].keys()),N))\n",
    "                contra = np.zeros((len(dat['contra_deg'].keys()),N))\n",
    "                total = np.zeros((len(dat['total_deg'].keys()),N))\n",
    "                for idx, d in enumerate(dat['ipso_deg']):\n",
    "                    ipsi[idx, :] = dat['ipso_deg'][d]\n",
    "                    contra[idx, :] = dat['contra_deg'][d]                    \n",
    "                    total[idx, :] = dat['total_deg'][d]\n",
    "                ipsi_avg = np.mean(ipsi, axis=0)\n",
    "                contra_avg = np.mean(contra, axis=0)\n",
    "                total_avg = np.mean(total, axis=0)\n",
    "                avg = {'ipso_deg': ipsi_avg, 'contra_deg': contra_avg,\n",
    "                       'total_deg': total_avg}\n",
    "            elif stat == 'study_mean_connectome':\n",
    "                dat_reduced = np.array([dat[i,j]\n",
    "                                        for i in np.arange(0, dat.shape[0])\n",
    "                                        for j in np.arange(i, dat.shape[1])])\n",
    "                avg = dat_reduced[np.where(dat_reduced>0)]\n",
    "            elif stat == 'number_non_zeros':\n",
    "                avg = np.array(dat.values())\n",
    "            else:\n",
    "                array = np.zeros((len(dat.keys()),N))\n",
    "                for idx, d in enumerate(dat):\n",
    "                    array[idx, :] = dat[d]\n",
    "                avg = np.mean(array, axis=0)\n",
    "            \n",
    "            # place in dict in same format that we grabbed it\n",
    "            average_dict[dset] = avg\n",
    "\n",
    "        # save new dict of averages\n",
    "        if stat == 'degree_distribution':\n",
    "            # reorganize\n",
    "            tmp = average_dict.keys()[0]\n",
    "            new = OrderedDict()\n",
    "            for key in average_dict[tmp].keys():\n",
    "                new[key] = {d: average_dict[d][key] for d in average_dict.keys()}\n",
    "            average_dict = new\n",
    "        elif stat == 'study_mean_connectome':\n",
    "            stat = 'edge_weight'\n",
    "        f = open('{}/avg_{}.pkl'.format(op, stat), 'wb')\n",
    "        pkl.dump({stat: average_dict}, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: betweenness_centrality\n",
      "Analyzing: clustering_coefficients\n",
      "Analyzing: degree_distribution\n",
      "Analyzing: edge_weight\n",
      "Evaluating by proxy of mean connectome -- cannot average unequal lists\n",
      "Analyzing: eigen_sequence\n",
      "Analyzing: locality_statistic\n",
      "Analyzing: number_non_zeros\n",
      "Analyzing: study_mean_connectome\n"
     ]
    }
   ],
   "source": [
    "dat = avg_data(dpath, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rgb(254,232,200)', 'rgb(253,212,158)', 'rgb(253,187,132)', 'rgb(252,141,89)', 'rgb(239,101,72)', 'rgb(215,48,31)', 'rgb(179,0,0)', 'rgb(127,0,0)', 'rgb(90,0,0)', 'rgb(30,0,0)']\n",
      "['rgb(254,232,200)', 'rgb(253,212,158)', 'rgb(253,187,132)', 'rgb(252,141,89)', 'rgb(239,101,72)', 'rgb(215,48,31)', 'rgb(179,0,0)', 'rgb(127,0,0)', 'rgb(90,0,0)', 'rgb(30,0,0)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:rgb(254,232,200);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(253,212,158);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(253,187,132);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(252,141,89);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(239,101,72);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(215,48,31);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(179,0,0);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(127,0,0);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(90,0,0);height:20px;width:20px;display:inline-block;\"></div><div style=\"background-color:rgb(30,0,0);height:20px;width:20px;display:inline-block;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "#categorical 10\n",
    "# cols = cl.scales['11']['qual']['Paired']\n",
    "# cols = {d:cols[idx] for idx, d in enumerate(dsets)}\n",
    "# HTML(cl.to_html(cols.values()))\n",
    "\n",
    "#sequential orange-red 10\n",
    "cols = dc(cl.scales['9']['seq']['OrRd'])\n",
    "cols = cols[1:]\n",
    "cols = cols + ['rgb(90,0,0)', 'rgb(30,0,0)']\n",
    "# print(len(cols))\n",
    "print(cols)\n",
    "cols2 = OrderedDict()\n",
    "for idx, d in enumerate(dsets):\n",
    "    cols2[d] = cols[idx]\n",
    "cols = cols2\n",
    "print(cols.values())\n",
    "HTML(cl.to_html(cols.values()))\n",
    "\n",
    "#my categorical 10\n",
    "# cols = ['rgba(228,26,28,{})', 'rgba(55,126,184,{})', 'rgba(77,175,74,{})',\n",
    "#         'rgba(152,78,163,{})', 'rgba(166,86,40,{})', 'rgba(247,129,191,{})',\n",
    "#         'rgba(255,204,0,{})', 'rgba(136,136,136,{})', 'rgba(55,224,169,{})',\n",
    "#         'rgba(0,85,85,{})']\n",
    "# cols = {d:cols[idx] for idx, d in enumerate(dsets)}\n",
    "\n",
    "#sequential greys 13\n",
    "# cols = ['#dedede', '#cdcdcd', '#bcbcbc', '#ababab', '#9a9a9a',\n",
    "#         '#898989', '#787878', '#676767', '#565656', '#454545',\n",
    "#         '#343434', '#232323', '#121212']\n",
    "\n",
    "#sequential blue-green 13\n",
    "# cols = cl.scales['9']['seq']['GnBu']\n",
    "# cols = cols[2:4] + ['rgb(141,211,184)'] + cols[4:5] + ['rgb(101,182,192)'] + cols[5:6] +\\\n",
    "#        ['rgb(52,152,200)'] + cols[6:7] + ['rgb(21,121,181)'] + cols[7:] + ['rgb(6,55,100)', 'rgb(5,42,82)']\n",
    "# HTML(cl.to_html(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('NKI1', 'rgb(254,232,200)'),\n",
       "             ('KKI2009', 'rgb(253,212,158)'),\n",
       "             ('HNU1', 'rgb(253,187,132)'),\n",
       "             ('BNU3', 'rgb(252,141,89)'),\n",
       "             ('BNU1', 'rgb(239,101,72)'),\n",
       "             ('Templeton114', 'rgb(215,48,31)'),\n",
       "             ('NKIENH', 'rgb(179,0,0)'),\n",
       "             ('SWU4', 'rgb(127,0,0)'),\n",
       "             ('Templeton255', 'rgb(90,0,0)'),\n",
       "             ('MRN1313', 'rgb(30,0,0)')])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[ 1.80334743  1.83271775  2.04742614  2.31768167  2.43380431  2.85105962\n",
      "  3.18338953  3.26566889  3.33094643  4.31574913]\n"
     ]
    }
   ],
   "source": [
    "normfactor = np.min(nsubs)\n",
    "relsize = 1.4*np.log2(np.array(nsubs))/np.log10(totalsubs)\n",
    "print normfactor\n",
    "print relsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "[32 67 33 68 19 54  5 40 21 56 20 55 11 46 14 49  8 43  6 41 34 69 26 61 27\n",
      " 62 15 50 18 53 13 48 12 47  2 37  1 36 31 66 29 64  9 44  7 42 22 57 16 51\n",
      " 30 65 17 52 25 60 10 45 24 59 23 58  3 38 28 63  4 39  0 35]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lh-unknown',\n",
       " 'lh-bankssts',\n",
       " 'lh-caudalanteriorcingulate',\n",
       " 'lh-caudalmiddlefrontal',\n",
       " 'lh-corpuscallosum',\n",
       " 'lh-cuneus',\n",
       " 'lh-entorhinal',\n",
       " 'lh-fusiform',\n",
       " 'lh-inferiorparietal',\n",
       " 'lh-inferiortemporal',\n",
       " 'lh-isthmuscingulate',\n",
       " 'lh-lateraloccipital',\n",
       " 'lh-lateralorbitofrontal',\n",
       " 'lh-lingual',\n",
       " 'lh-medialorbitofrontal',\n",
       " 'lh-middletemporal',\n",
       " 'lh-parahippocampal',\n",
       " 'lh-paracentral',\n",
       " 'lh-parsopercularis',\n",
       " 'lh-parsorbitalis',\n",
       " 'lh-parstriangularis',\n",
       " 'lh-pericalcarine',\n",
       " 'lh-postcentral',\n",
       " 'lh-posteriorcingulate',\n",
       " 'lh-precentral',\n",
       " 'lh-precuneus',\n",
       " 'lh-rostralanteriorcingulate',\n",
       " 'lh-rostralmiddlefrontal',\n",
       " 'lh-superiorfrontal',\n",
       " 'lh-superiorparietal',\n",
       " 'lh-superiortemporal',\n",
       " 'lh-supramarginal',\n",
       " 'lh-frontalpole',\n",
       " 'lh-temporalpole',\n",
       " 'lh-transversetemporal',\n",
       " 'rh-unknown',\n",
       " 'rh-bankssts',\n",
       " 'rh-caudalanteriorcingulate',\n",
       " 'rh-caudalmiddlefrontal',\n",
       " 'rh-corpuscallosum',\n",
       " 'rh-cuneus',\n",
       " 'rh-entorhinal',\n",
       " 'rh-fusiform',\n",
       " 'rh-inferiorparietal',\n",
       " 'rh-inferiortemporal',\n",
       " 'rh-isthmuscingulate',\n",
       " 'rh-lateraloccipital',\n",
       " 'rh-lateralorbitofrontal',\n",
       " 'rh-lingual',\n",
       " 'rh-medialorbitofrontal',\n",
       " 'rh-middletemporal',\n",
       " 'rh-parahippocampal',\n",
       " 'rh-paracentral',\n",
       " 'rh-parsopercularis',\n",
       " 'rh-parsorbitalis',\n",
       " 'rh-parstriangularis',\n",
       " 'rh-pericalcarine',\n",
       " 'rh-postcentral',\n",
       " 'rh-posteriorcingulate',\n",
       " 'rh-precentral',\n",
       " 'rh-precuneus',\n",
       " 'rh-rostralanteriorcingulate',\n",
       " 'rh-rostralmiddlefrontal',\n",
       " 'rh-superiorfrontal',\n",
       " 'rh-superiorparietal',\n",
       " 'rh-superiortemporal',\n",
       " 'rh-supramarginal',\n",
       " 'rh-frontalpole',\n",
       " 'rh-temporalpole',\n",
       " 'rh-transversetemporal']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnames = [name for name in os.listdir(dpath+'/avg')\n",
    "          if os.path.splitext(name)[1] == '.pkl' and 'degree' in name]\n",
    "fnames = sorted(fnames)\n",
    "paths = [os.path.join(dpath+'/avg', item) for item in fnames]\n",
    "keys = [\"_\".join(n.split('.')[0].split('_')[1:]) for n in fnames]\n",
    "for idx, curr in enumerate(paths):\n",
    "    f = open(curr)\n",
    "    dat = pkl.load(f)[keys[idx]]\n",
    "    f.close()\n",
    "    break\n",
    "\n",
    "from itertools import chain, izip\n",
    "\n",
    "\n",
    "d = dat['total_deg']['BNU1']\n",
    "h1 = np.array(sorted(range(len(d[:35])), key=lambda k: d[k]))\n",
    "h2 = h1[:]+35\n",
    "ordering = np.concatenate((h1,h2))\n",
    "ordering = np.array(list(chain.from_iterable(izip(h1, h2))))\n",
    "print len(ordering)\n",
    "print ordering\n",
    "\n",
    "\n",
    "with open('./desikan.txt') as fil:\n",
    "        rois = fil.read().split('\\n')\n",
    "rois\n",
    "# dat = [0, 1, 2, 3, 8, 5, 6, 7]\n",
    "# print sorted(range(len(dat)), key=lambda k: dat[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering = np.arange(70)\n",
    "# ordering2 = sorted(ordering, reverse=True)\n",
    "# ordering[ordering2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degrees(dats, name=None, ylab=None, xlab=None, hemi=False):\n",
    "    data = list()\n",
    "    if hemi:\n",
    "        main = dats['ipso_deg']\n",
    "        contra = dats['contra_deg']\n",
    "    else:\n",
    "        main = dats['total_deg']\n",
    "    al = (4.0/len(main.keys()))\n",
    "\n",
    "    for idx, key in enumerate(dsets):\n",
    "        lgth = len(main[key])\n",
    "        data += [\n",
    "                 Scatter(\n",
    "                         x=np.linspace(1, lgth, lgth),\n",
    "                         y=main[key][ordering],\n",
    "                         line=Line(\n",
    "                                   color=cols[key],\n",
    "#                                    width=relsize[idx],\n",
    "                                  ),\n",
    "                         hoverinfo='x',\n",
    "                         name=key,\n",
    "                         showlegend=True,\n",
    "                         legendgroup=key\n",
    "                        )\n",
    "                ]\n",
    "        if hemi:\n",
    "            data += [\n",
    "                     Scatter(\n",
    "                             x=np.linspace(1, lgth, lgth),\n",
    "                             y=contra[key][ordering],\n",
    "                             line=Line(\n",
    "                                       color=cols[key],\n",
    "#                                        width=relsize[idx],\n",
    "                                       dash='dash'\n",
    "                                      ),\n",
    "                             hoverinfo='x',\n",
    "                             name=key,\n",
    "                             showlegend=False,\n",
    "                             legendgroup=key\n",
    "                            )\n",
    "                    ]\n",
    "    fig = Figure(data=data)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_series(stat, name=None, ylab=None, xlab=None, sort=False, leg=False, reverse=False):\n",
    "    data = list()\n",
    "    for idx, key in enumerate(dsets):\n",
    "        ys = stat[key]\n",
    "        if sort:\n",
    "            hov = 'x'\n",
    "            ys = np.array(sorted(ys, reverse=reverse))\n",
    "        else:\n",
    "            ys = ys[ordering]\n",
    "            if idx == 0:\n",
    "                hov = 'text'\n",
    "            else:\n",
    "                hov = 'none'\n",
    "        data += [\n",
    "                 Scatter(\n",
    "                         x=np.linspace(1, len(ys), len(ys)),\n",
    "                         y=ys,\n",
    "                         line=Line(\n",
    "                                   color=cols[key],\n",
    "#                                    width=relsize[idx],\n",
    "                                  ),\n",
    "                         hoverinfo=hov,\n",
    "                         text=[rois[ordi] for ordi in ordering],\n",
    "                         # text= ordering+1,\n",
    "                         name=key,\n",
    "                         showlegend=False,\n",
    "                         legendgroup=key\n",
    "                        )\n",
    "                ]\n",
    "    fig = Figure(data=data)\n",
    "    return fig\n",
    "\n",
    "def plot_jitter_scatter(stat, name=None, ylab=None, xlab=None):\n",
    "    data = list()\n",
    "    ys = [stat[key] for key in dsets]\n",
    "    xs = np.linspace(-0.5, 0.5, len(ys))\n",
    "    for idx, y in enumerate(ys):\n",
    "        data += [\n",
    "                 Scatter(\n",
    "                         x=0.05*np.random.rand(len(ys[idx]))+xs[idx],\n",
    "                         y=ys[idx],\n",
    "                         mode='markers',\n",
    "                         marker=Marker(\n",
    "                            color=cols[dsets[idx]],\n",
    "                            size=5,\n",
    "#                             size=relsize[idx],\n",
    "#                             opacity=0.2,\n",
    "                         ),\n",
    "                         hoverinfo='text',\n",
    "                         text=dsets[idx],\n",
    "                         name='{} ({})'.format(dsets[idx], nsubs[idx]),\n",
    "                         showlegend=True,\n",
    "                         legendgroup=dsets[idx]\n",
    "                        )\n",
    "                ]\n",
    "    fig = Figure(data=data)\n",
    "    return fig\n",
    "\n",
    "# def plot_rugdensity(stat, name=None, ylab=None, xlab=None):\n",
    "#     series = [stat[dset] for dset in dsets]\n",
    "#     dens = gaussian_kde(series)\n",
    "#     x = np.linspace(np.min(series), np.max(series), 100)\n",
    "#     y = dens.evaluate(x)*np.max(series)\n",
    "\n",
    "#     d_rug = Scatter(\n",
    "#                 x=series,\n",
    "#                 y=[0]*len(series),\n",
    "#                 mode='markers',\n",
    "#                 marker=Marker(\n",
    "#                          color=[cols[dset] for dset in dsets],\n",
    "#                          size=10,\n",
    "#                        ),\n",
    "#                 name=name,\n",
    "#                 text=dsets,\n",
    "#                 hoverinfo='text',\n",
    "#                 showlegend=False\n",
    "#           )\n",
    "\n",
    "#     d_dens = Scatter(\n",
    "#                 x=x,\n",
    "#                 y=y,\n",
    "#                 line=Line(\n",
    "#                        color='rgba(0,0,0,0.6)'\n",
    "#                      ),\n",
    "#                 hoverinfo='x',\n",
    "#                 name=name,\n",
    "#                 showlegend=False\n",
    "#            )\n",
    "#     data = [d_dens, d_rug]\n",
    "#     fig = Figure(data=data)\n",
    "#     return fig\n",
    "\n",
    "def make_panel_plot(basepath, dataset=None, atlas=None,\n",
    "                    log=True, hemispheres=False):\n",
    "    fnames = [name for name in os.listdir(basepath)\n",
    "              if os.path.splitext(name)[1] == '.pkl']\n",
    "    fnames = sorted(fnames)\n",
    "    paths = [os.path.join(basepath, item) for item in fnames]\n",
    "    keys = [\"_\".join(n.split('.')[0].split('_')[1:]) for n in fnames]\n",
    "    labs = ['Betweenness Centrality', 'Clustering Coefficient', 'Degree',\n",
    "            'Edge Weight', 'Eigenvalue', 'Locality Statistic-1',\n",
    "            'Number of Non-zeros', 'Mean Connectome']\n",
    "\n",
    "    traces = list(())\n",
    "    for idx, curr in enumerate(paths):\n",
    "        f = open(curr)\n",
    "        dat = pkl.load(f)[keys[idx]]\n",
    "        f.close()\n",
    "        if keys[idx] == 'number_non_zeros':\n",
    "#             fig = plot_rugdensity(dat)\n",
    "            fig = plot_jitter_scatter(dat)\n",
    "        elif keys[idx] == 'edge_weight':\n",
    "            edges = np.max([len(dat[i]) for i in dat.keys()])\n",
    "            fig = plot_series(dat, sort=True)\n",
    "        elif keys[idx] == 'degree_distribution':\n",
    "            if not hemispheres:\n",
    "                tmp = dat['total_deg']\n",
    "                fig = plot_series(tmp, leg=True)\n",
    "            else:\n",
    "                fig = plot_degrees(dat, hemi=hemispheres)\n",
    "                anno = [dict(x=dims/3,\n",
    "                             y=4*dims/7,\n",
    "                             xref='x3',\n",
    "                             yref='y3',\n",
    "                             text='ipsilateral',\n",
    "                             showarrow=False,\n",
    "                             font=dict(color='rgb(0,0,0)',\n",
    "                                       size=14)),\n",
    "                        dict(x=dims/3,\n",
    "                             y=3.7*dims/7,\n",
    "                             xref='x3',\n",
    "                             yref='y3',\n",
    "                             text='contralateral',\n",
    "                             showarrow=False,\n",
    "                             font=dict(color='rgb(0,0,0)',\n",
    "                                       size=14))]\n",
    "        else:\n",
    "            dims = len(dat.values()[0])\n",
    "            if keys[idx] == 'eigen_sequence':\n",
    "                fig = plot_series(dat, sort=True, reverse=True)\n",
    "            else:\n",
    "                fig = plot_series(dat)\n",
    "        traces += [pp.fig_to_trace(fig)]\n",
    "\n",
    "    multi = pp.traces_to_panels(traces)\n",
    "    for idx, curr, in enumerate(paths):\n",
    "        key = 'axis%d' % (idx+1)\n",
    "        d = multi.layout['x'+key]['domain']\n",
    "        multi.layout['x'+key]['domain'] = [d[0], d[1]-0.0125]\n",
    "        multi.layout['x'+key]['zeroline'] = False\n",
    "        multi.layout['y'+key]['zeroline'] = False\n",
    "        multi.layout['y'+key]['title'] = labs[idx]\n",
    "        multi.layout['x'+key]['title'] = 'Node'\n",
    "        multi.layout['x'+key]['nticks'] = 3\n",
    "        multi.layout['y'+key]['nticks'] = 3\n",
    "        if idx in [0, 1, 2, 3, 5]:\n",
    "            multi.layout['x'+key]['range'] = [1, dims]\n",
    "            multi.layout['x'+key]['tickvals'] = [1, dims/2, dims]\n",
    "            if idx in [2]:\n",
    "                if hemispheres:\n",
    "                    multi.layout['annotations'] = anno\n",
    "            elif log:\n",
    "                multi.layout['y'+key]['type'] = 'log'\n",
    "                multi.layout['y'+key]['title'] += ' (log scale)'\n",
    "        if idx in [3]:\n",
    "            multi.layout['x'+key]['range'] = [1, edges]\n",
    "            multi.layout['x'+key]['tickvals'] = [1, edges/2, edges]\n",
    "            multi.layout['x'+key]['title'] = 'Edge'\n",
    "        if idx in [4]:\n",
    "            multi.layout['x'+key]['range'] = [1, dims]\n",
    "            multi.layout['x'+key]['tickvals'] = [1, dims/2, dims]\n",
    "            multi.layout['x'+key]['title'] = 'Dimension'\n",
    "        if idx in [6]:\n",
    "            multi.layout['x'+key]['title'] = 'Dataset'\n",
    "            multi.layout['y'+key]['range'] = [0, 1500]\n",
    "            multi.layout['x'+key]['tickvals'] = [0]\n",
    "            multi.layout['x'+key]['ticktext'] = ['']\n",
    "        if idx in [7]:\n",
    "            multi.layout['y'+key]['title'] = None\n",
    "            multi.layout['x'+key]['title'] = labs[idx]\n",
    "            multi.layout['y'+key]['autorange'] = 'reversed'\n",
    "            multi.layout['x'+key]['tickvals'] = [0, dims/2-1, dims-1]\n",
    "            multi.layout['y'+key]['tickvals'] = [0, dims/2-1, dims-1]\n",
    "            multi.layout['x'+key]['ticktext'] = [1, dims/2, dims]\n",
    "            multi.layout['y'+key]['ticktext'] = [1, dims/2, dims]\n",
    "            if log:\n",
    "                multi.layout['x'+key]['title'] += ' (log10)'\n",
    "\n",
    "    if dataset is not None and atlas is not None:\n",
    "        if atlas == 'desikan':\n",
    "            atlas = atlas.capitalize()\n",
    "        tit = dataset + ' (' + atlas + ' parcellation)'\n",
    "    else:\n",
    "        tit = None\n",
    "        \n",
    "    multi.layout['showlegend'] = True\n",
    "    multi.layout['legend']['orientation']= 'v'\n",
    "    multi.layout['legend']['xanchor'] = 'x7'\n",
    "    multi.layout['legend']['yanchor'] = 'y8'\n",
    "    multi.layout['legend']['x'] = 0.78\n",
    "    multi.layout['legend']['y'] = -0.17\n",
    "    multi.layout['legend']['tracegroupgap']= 0\n",
    "    multi.layout['legend']['font'] =  {'size':14}\n",
    "    \n",
    "    anno = [dict(x=0.97, y=0.46, xref='paper', yref='paper',\n",
    "                 text=\"Dataset (Number of Subjects)\", showarrow=False,\n",
    "                 font=dict(color=\"#28282e\", size=14))]\n",
    "    multi.layout.annotations = anno\n",
    "    multi.layout['title'] = tit\n",
    "    return multi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the format of your plot grid:\n",
      "[ (1,1) x1,y1 ]  [ (1,2) x2,y2 ]  [ (1,3) x3,y3 ]  [ (1,4) x4,y4 ]\n",
      "[ (2,1) x5,y5 ]  [ (2,2) x6,y6 ]  [ (2,3) x7,y7 ]  [ (2,4) x8,y8 ]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'file:///Users/gkiar/code/ocp/ndmg-paper/code/multisite_graphs/multisite_sorted_dset.html'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas = 'Desikan'\n",
    "multi = make_panel_plot(dpath+'/avg', hemispheres=False, atlas=atlas, dataset='Multiple Datasets')\n",
    "\n",
    "# iplot(multi)\n",
    "plot(multi, validate=False,\n",
    "     filename='/Users/gkiar/code/ocp/ndmg-paper/code/multisite_graphs/multisite_sorted_dset.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ndmg",
   "language": "python",
   "name": "ndmg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
